{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":33657,"databundleVersionId":3279164,"sourceType":"competition"},{"sourceId":3337936,"sourceType":"datasetVersion","datasetId":2015496},{"sourceId":3693646,"sourceType":"datasetVersion","datasetId":2210196}],"dockerImageVersionId":30527,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# U.S. Patent Phrase to Phrase Matching With DeBERTaV3 and YouTube Walkthrough\n---\n## Table of Contents\n* [Introduction](#introduction)\n* [YouTube Walkthrough](#youtube)\n* [Before You Begin](#begin)\n* [Data and Files](#datafiles)\n* [Implementation](#implementation)\n    * [Imports](#datafile)\n    * [Hyperparameter Definitions](#hyperparam)\n    * [EDA](#eda)\n    * [Merge Datasets](#merge)\n    * [Model and Tokenizer Definition](#modeltokenizer)\n    * [Dataset and Dataloader Implementation](#dataobj)\n    * [Train Loop](#train)\n    * [Free-up Memory](#freememo)\n    * [Prediction Loop](#predict)\n    * [Submission File Preperation](#submit)\n* [Submission](#submit)\n* [References](#references)","metadata":{}},{"cell_type":"markdown","source":"## Introduction <a class=\"anchor\" id=\"introduction\"></a>\nIn this competition our aim is to predict the similarity between two given texts. Between *anchor* and the *target*. Formally: *In this competition, you will train your models on a novel semantic similarity dataset to extract relevant information by matching key phrases in patent documents.* \n\nWe'll **treat this task as a sequence classification problem**. However instead of assigning a class to each passage, we'll assign them scores with regression loss. Model scores are evaluated with *pearson correlation coefficient*.\n\n---\nAny question and suggestion is appreciated. You can put them in the comments.","metadata":{}},{"cell_type":"markdown","source":"## YouTube Walkthrough <a class=\"anchor\" id=\"youtube\"></a>\nIf you want to see me implement and explain this notebook live, watch the YouTube video below.\n\n#### Kaggle Competition Walkthrough [NLP] - U.S. Patent Phrase to Phrase Matching - CommonLit Readability Prize\n[<img src=\"https://i.imgur.com/FQZRfBG.png\" width=\"640\" height=\"360\"/>](https://www.youtube.com/watch?v=o0mkv52nazI)","metadata":{}},{"cell_type":"markdown","source":"## Before You Begin <a class=\"anchor\" id=\"begin\"></a>\n\n* **Toggle *internet off* button for this notebook.** This competition requires the notebook to be offline. In order to submit your solution you have to turn off internet for this notebook. You can do it from the right panel.\n\n* Add pretrained [DeBERTaV3](https://www.kaggle.com/datasets/debarshichanda/debertav3base). Since the internet is off for this notebook we need a way to load our DeBERTaV3 model offline. To do that go to the right panel, click *data*, click *add-data* and type *debertav3base*. Add the resulting dataset.\n\n* Add [cpc-codes](https://www.kaggle.com/datasets/xhlulu/cpc-codes). We'll merge this additional data with the competition data. To do that go to the right panel, click *data*, click *add-data* and type *cpc-codes*. Add the resulting dataset.","metadata":{}},{"cell_type":"markdown","source":"## Data and Files <a class=\"anchor\" id=\"datafiles\"></a>\n\nWe're given 3 files as inputs. *train.csv* which contains training data, *test.csv* which contains test data and *sample_submission.csv* which contains the submission format. Columns that files contain are:\n\n* `id` - unique ID for excerpt\n* `anchor` - anchor of the patent we're matching\n* `target` - target of the patent we're matching\n* `context` - patent class identifier\n* `score` - similarity score (we'll predict this)\n\n\n1. **train.csv**: contains training data\n    * `id`\n    * `anchor`\n    * `target`\n    * `context`\n    * `score` \n  \n  \n2. **test.csv** contains the test data\n    * `id`\n    * `anchor`\n    * `target`\n    * `context`  \n    \n    \n3. **sample_submission.csv** contains submission format\n    * `id`\n    * `score`\n    \n---\nAdditionally we loaded *titles.csv* from *cpc-codes* dataset. Columns that files contain are:\n\n* code - patent class identifier (corresponds to *context* of the main data)\n* title - title of the patent\n* section - section identifier of the patent\n* class - class of the patent\n* subclass - subclass of the patent\n* group - group of the patent\n* main_group - main group op the patent\n\n\n1. **titles.csv**: only file\n    * code\n    * title\n    * section\n    * class\n    * subclass\n    * group\n    * main_group","metadata":{}},{"cell_type":"markdown","source":"## Implementation <a class=\"anchor\" id=\"implementation\"></a>","metadata":{}},{"cell_type":"markdown","source":"### Imports <a class=\"anchor\" id=\"imports\"></a>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport transformers\nfrom transformers import DebertaV2TokenizerFast, DebertaV2ForSequenceClassification\nimport torch\nfrom torch import optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchmetrics.regression import PearsonCorrCoef\nimport numpy as np\nimport random\nimport timeit\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameter Definitions <a class=\"anchor\" id=\"hyperparam\"></a>","metadata":{}},{"cell_type":"code","source":"RANDOM_SEED = 42\nMODEL_PATH = \"/kaggle/input/debertav3base\"\nMAX_LENGTH = 256\nBATCH_SIZE = 64\nLEARNING_RATE = 2e-5\nEPOCHS = 2\n\nrandom.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed_all(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntransformers.utils.logging.set_verbosity_error() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA <a class=\"anchor\" id=\"eda\"></a>","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/us-patent-phrase-to-phrase-matching/sample_submission.csv\")\npatents_df = pd.read_csv(\"/kaggle/input/cpc-codes/titles.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patents_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge Datasets <a class=\"anchor\" id=\"merge\"></a>","metadata":{}},{"cell_type":"code","source":"updated_train_df = train_df.merge(patents_df, left_on='context', right_on='code')\nupdated_train_df[\"input\"] = updated_train_df[\"title\"] + \" \" + updated_train_df[\"anchor\"]\nupdated_train_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"updated_test_df = test_df.merge(patents_df, left_on='context', right_on='code')\nupdated_test_df[\"input\"] = updated_test_df[\"title\"] + \" \" + updated_test_df[\"anchor\"]\nupdated_train_df.tail()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model and Tokenizer Definition <a class=\"anchor\" id=\"modeltokenizer\"></a>","metadata":{}},{"cell_type":"code","source":"tokenizer = DebertaV2TokenizerFast.from_pretrained(MODEL_PATH)\nmodel = DebertaV2ForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=1).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset and Dataloader Implementation <a class=\"anchor\" id=\"dataobj\"></a>\n\nYou may realize we added two inputs to the `tokenizer`. By this, the tokenizer combines them as `text1 [SEP] text2`. Hence we can work with both.","metadata":{}},{"cell_type":"code","source":"class PhraseTrainDataset(Dataset):\n    def __init__(self, inputs, targets, scores, tokenizer):\n        self.scores = scores\n        self.encodings = tokenizer(inputs, targets, padding=True, truncation=True, max_length=MAX_LENGTH)\n\n    def __getitem__(self, idx):\n        out_dic = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        out_dic[\"scores\"] = self.scores[idx]\n        return out_dic\n    \n    def __len__(self):\n        return len(self.scores)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PhraseSubmitDataset(Dataset):\n    def __init__(self, inputs, targets, ids, tokenizer):\n        self.ids = ids\n        self.encodings = tokenizer(inputs, targets, padding=True, truncation=True, max_length=MAX_LENGTH)\n\n    def __getitem__(self, idx):\n        out_dic = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        out_dic[\"ids\"] = self.ids[idx]\n        return out_dic\n    \n    def __len__(self):\n        return len(self.ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = PhraseTrainDataset(updated_train_df[\"input\"].to_list(), updated_train_df[\"target\"].to_list(), updated_train_df[\"score\"].to_list(), tokenizer)\ntest_dataset = PhraseSubmitDataset(updated_test_df[\"input\"].to_list(), updated_test_df[\"target\"].to_list(), updated_test_df[\"id\"].to_list(), tokenizer)\nprint(\"-\"*30)\nprint(len(dataset))\nprint(dataset[0])\nprint(\"-\"*30)\nprint(len(test_dataset))\nprint(test_dataset[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = torch.Generator().manual_seed(RANDOM_SEED)\ntrain_dataset, val_dataset = random_split(dataset, [0.9, 0.1], generator=generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(dataset=train_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)\n\nval_dataloader = DataLoader(dataset=val_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=True)\n\ntest_dataloader = DataLoader(dataset=test_dataset,\n                              batch_size=BATCH_SIZE,\n                              shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training Loop <a class=\"anchor\" id=\"train\"></a>","metadata":{}},{"cell_type":"code","source":"optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\npearson = PearsonCorrCoef()\n\nstart = timeit.default_timer() \nfor epoch in tqdm(range(EPOCHS), position=0, leave=True):\n    model.train()\n    train_running_loss = 0 \n    for idx, sample in enumerate(tqdm(train_dataloader, position=0, leave=True)):\n        input_ids = sample['input_ids'].to(device)\n        attention_mask = sample['attention_mask'].to(device)\n        targets = sample[\"scores\"].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_running_loss += loss.item()\n    train_loss = train_running_loss / (idx + 1)\n\n    model.eval()\n    val_running_loss = 0 \n    preds = []\n    golds = []\n    with torch.no_grad():\n        for idx, sample in enumerate(tqdm(val_dataloader, position=0, leave=True)):\n            input_ids = sample['input_ids'].to(device)\n            attention_mask = sample['attention_mask'].to(device)\n            targets = sample[\"scores\"].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=targets)\n            \n            preds.extend([float(i) for i in outputs[\"logits\"].squeeze()])\n            golds.extend([float(i) for i in targets])\n            \n            val_running_loss += outputs.loss.item()\n        val_loss = val_running_loss / (idx + 1)\n\n    print(\"-\"*30)\n    print(f\"Pearson Score: {float(pearson(torch.tensor(preds), torch.tensor(golds))):.4f}\")\n    print(f\"Train Loss EPOCH {epoch+1}: {train_loss:.4f}\")\n    print(f\"Valid Loss EPOCH {epoch+1}: {val_loss:.4f}\")\n    print(\"-\"*30)\nstop = timeit.default_timer()\nprint(f\"Training Time: {stop-start:.2f}s\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Free-up Memory <a class=\"anchor\" id=\"freememo\"></a>","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction Loop <a class=\"anchor\" id=\"predict\"></a>","metadata":{}},{"cell_type":"code","source":"preds = []\nids = []\nmodel.eval()\nwith torch.no_grad():\n    for idx, sample in enumerate(tqdm(test_dataloader, position=0, leave=True)):\n        input_ids = sample['input_ids'].to(device)\n        attention_mask = sample['attention_mask'].to(device)\n        ids.extend(sample[\"ids\"])\n        \n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        preds.extend([float(i) for i in outputs[\"logits\"].squeeze()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Submission File Preperartion <a class=\"anchor\" id=\"submit\"></a>","metadata":{}},{"cell_type":"code","source":"submission_df = pd.DataFrame(list(zip(ids, preds)),\n               columns =[\"id\", \"score\"])\nsubmission_df.to_csv(\"submission.csv\", index=False)\nsubmission_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission <a class=\"anchor\" id=\"submission\"></a>\n\nIf your notebook runs smoothly you can go to the right panel and click submit. Congratulations :)     \nAny question and suggestion is appreciated. You can put them in the comments.","metadata":{}},{"cell_type":"markdown","source":"## References <a class=\"anchor\" id=\"references\"></a>\n\n* https://www.kaggle.com/code/ksork6s4/uspppm-bert-for-patents-baseline-train","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/8gNhPcv.jpg\"/>","metadata":{}}]}